[options]
; env: SimpleAvoid, NH_center, NH_tree, City
env = airsim
env_name = attack
num_of_drone = 4
discrete_grid_x = 20
discrete_grid_y = 20
; dynamics: SimpleFixedwing, SimpleMultirotor, Multirotor
dynamic_name =  Multirotor
navigation_3d = False
reward_type = reward_with_action
; algorithm: TD3, PPO, SAC
algo = MAPPO
total_timesteps = 150000
; policy: CNN_FC, CNN_GAP, CNN_GAP_BN, No_CNN, CNN_MobileNet
policy_name = No_CNN
cnn_feature_num = 25
ip = 127.0.0.1
keyboard_debug = False
generate_q_map = False
q_map_save_steps = 500
velocity_step = 0.02
vz_step = 0.05
yaw_step = 5
user_name = lsh_ai
acc_step = 0.001
az_step = 0.05
ayaw_step = 18
subscriber = aaa@hotmail.com bbb@XX.webmail ccc@test.org
init_yaw_degree = 0 -90 -90 180
world_clock = 20

[algorithm]
algorithm_name = rmappo
use_recurrent_policy = True
use_naive_recurrent_policy = False
share_policy = True
cuda = True
n_training_threads = 1
n_rollout_threads = 1
n_render_rollout_threads = 1
n_eval_rollout_threads = 1
cuda_deterministic = True
seed = 10
use_eval = False
use_centralized_V = True
use_obs_instead_of_state = True
num_env_steps = 50000
episode_length = 500
use_linear_lr_decay = 1
hidden_size = 64
use_render = True
recurrent_N = 1
save_interval = 10
eval_interval = 25
log_interval = 1
model_dir =
;    E:\\airsim_mappo\\onpolicy\\models
lr = 0.0007
critic_lr = 0.0007
opti_eps = 1e-5
weight_decay = 0
gain = 0.01
use_policy_active_masks = True
use_wandb = True
use_orthogonal = True
use_ReLU = False
use_popart = True
use_feature_normalization = True
stacked_frames = 1
layer_N = 1
clip_param = 0.2
ppo_epoch = 10
num_mini_batch = 1
data_chunk_length = 10
value_loss_coef = 1
entropy_coef = 0.01
max_grad_norm = 10.0
huber_delta = 10.0
use_max_grad_norm = True
use_clipped_value_loss = True
use_huber_loss = True
use_valuenorm = False
use_value_active_masks = True
gamma = 0.99
gae_lambda = 0.95
use_proper_time_limits = False
use_gae = True

[environment]
crash_distance = 2
accept_radius = 6
max_depth_meters = 20

screen_height = 80
screen_width = 100

[multirotor]
dt = 0.5
acc_xy_max = 2.0
v_xy_max = 2.0
v_xy_min = 0.0
v_z_max = 2.0
yaw_rate_max_deg = 90


[fixedwing]
dt = 0.1

[TD3]
gamma = 0.99
learning_rate = 1e-3
learning_starts = 2000
buffer_size = 50000
batch_size = 128
train_freq = 1
gradient_steps = 1
action_noise_sigma = 0.3

[PPO]
learning_rate = 1e-3

[SAC]
learning_rate = 1e-3
learning_starts = 2000
buffer_size = 50000
batch_size = 128
action_noise_sigma = 0.3
train_freq = 1
gradient_steps = 1
